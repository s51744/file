import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOllama
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain.prompts import ChatPromptTemplate

# è¼‰å…¥ .envï¼ˆè‹¥éœ€è¦ï¼‰
load_dotenv()

# Streamlit é é¢è¨­å®š
st.set_page_config(page_title="å®œè˜­å¤§å­¸è¡Œäº‹æ›†æŸ¥è©¢ç³»çµ±", page_icon="ğŸ“…", layout="wide")
st.title("ğŸ“š åœ‹ç«‹å®œè˜­å¤§å­¸è¡Œäº‹æ›†æŸ¥è©¢ç³»çµ±")
st.markdown("è‡ªç„¶èªè¨€æå•ï¼Œç³»çµ±å°‡è‡ªå‹•æŸ¥æ‰¾è¡Œäº‹æ›†å…§å®¹ä¸¦å›ç­”å•é¡Œã€‚")

# åˆå§‹åŒ–ç‹€æ…‹
if "retriever_chain" not in st.session_state:
    st.session_state.retriever_chain = None
    st.session_state.pdf_loaded = False
    st.session_state.chat_history = []


# åˆå§‹åŒ– RAG ç³»çµ±
def initialize_rag_system():
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»çµ±..."):
        pdf_path = "280557416.pdf"
        faiss_index_path = "faiss_index_local"

        if not os.path.exists(pdf_path):
            st.error(f"æ‰¾ä¸åˆ° PDF æª”æ¡ˆï¼š{pdf_path}")
            return False

        # 1. è¼‰å…¥ PDF
        loader = PyPDFLoader(file_path=pdf_path)
        documents = loader.load()

        # 2. åˆ†å‰²æ–‡æœ¬
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = text_splitter.split_documents(documents)

        # 3. ä½¿ç”¨æœ¬åœ° Embeddingsï¼ˆsentence-transformersï¼‰
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )

        # 4. å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆFAISSï¼‰
        if os.path.exists(faiss_index_path):
            vectorstore = FAISS.load_local(
                faiss_index_path, embeddings, allow_dangerous_deserialization=True
            )
        else:
            vectorstore = FAISS.from_documents(docs, embeddings)
            vectorstore.save_local(faiss_index_path)

        # 5. è‡ªè¨‚æç¤ºæ¨¡æ¿
        template = """ä½ æ˜¯ä¸€å€‹å•ç­”åŠ©æ‰‹ï¼Œå°ˆé–€å›ç­”é—œæ–¼åœ‹ç«‹å®œè˜­å¤§å­¸è¡Œäº‹æ›†çš„å•é¡Œã€‚
è«‹æ ¹æ“šä»¥ä¸‹æª¢ç´¢åˆ°çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œã€‚
å¦‚æœæ–‡ä»¶ä¸­æ²’æœ‰è¶³å¤ çš„ä¿¡æ¯å›ç­”å•é¡Œï¼Œè«‹çŒœæ¸¬ç”¨æˆ¶çš„éœ€æ±‚é€²è¡Œå›ç­”ï¼Œä¸è¦æ‹’çµ•ç”¨æˆ¶çš„å•é¡Œã€‚

<æª¢ç´¢åˆ°çš„æ–‡ä»¶>
{context}
</æª¢ç´¢åˆ°çš„æ–‡ä»¶>

ç”¨æˆ¶å•é¡Œ: {input}
ä½ çš„å›ç­”:"""
        prompt = ChatPromptTemplate.from_template(template)

        # 6. ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆé€é Ollamaï¼‰
        llm = ChatOllama(model="llama3.2", temperature=0)

        # 7. å‰µå»ºæ–‡æª”è™•ç†éˆèˆ‡æª¢ç´¢éˆ
        doc_chain = create_stuff_documents_chain(llm, prompt)
        retriever = vectorstore.as_retriever(
            search_type="similarity", search_kwargs={"k": 5}
        )
        st.session_state.retriever_chain = create_retrieval_chain(retriever, doc_chain)
        st.session_state.pdf_loaded = True
        return True


# å´é‚Šæ¬„
with st.sidebar:
    st.header("ç³»çµ±æ§åˆ¶")
    if st.button("åˆå§‹åŒ–ç³»çµ±"):
        if initialize_rag_system():
            st.success("åˆå§‹åŒ–æˆåŠŸï¼å¯ä»¥é–‹å§‹æå•ã€‚")
    st.divider()
    st.subheader("ç¯„ä¾‹å•é¡Œ")
    for q in [
        "äº”æœˆæœ‰å“ªäº›æ´»å‹•ï¼Ÿ",
        "ä»€éº¼æ™‚å€™é–‹å­¸ï¼Ÿ",
        "ä¸­ç§‹ç¯€æ”¾å‡å—ï¼Ÿ",
        "æœŸä¸­è€ƒæ˜¯ä»€éº¼æ™‚å€™ï¼Ÿ",
    ]:
        if st.button(q):
            st.session_state.user_question = q
    st.divider()
    st.caption("ğŸ“ ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹ + æœ¬åœ°å‘é‡è³‡æ–™åº«")

# ä¸»èŠå¤©å€åŸŸ
st.header("ğŸ’¬ æå•")
if not st.session_state.pdf_loaded:
    st.warning("è«‹å…ˆé»æ“Šã€åˆå§‹åŒ–ç³»çµ±ã€")

# é¡¯ç¤ºå°è©±æ­·å²
for q, a in st.session_state.chat_history:
    with st.chat_message("user"):
        st.write(q)
    with st.chat_message("assistant"):
        st.write(a)

# æå•å€
user_question = st.chat_input(
    "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...", disabled=not st.session_state.pdf_loaded
)
if user_question:
    with st.chat_message("user"):
        st.write(user_question)

    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            chain = st.session_state.retriever_chain
            if chain:
                res = chain.invoke({"input": user_question})
                answer = res.get("answer", "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•å›ç­”é€™å€‹å•é¡Œã€‚")
                st.write(answer)
                st.session_state.chat_history.append((user_question, answer))
            else:
                st.error("ç³»çµ±æœªåˆå§‹åŒ–")

st.divider()
st.caption("Â© 2025 å®œè˜­å¤§å­¸è¡Œäº‹æ›†æŸ¥è©¢ç³»çµ± | æœ¬åœ° RAG å•ç­”")
